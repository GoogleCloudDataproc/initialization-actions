{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting NYC Taxi Fares with RAPIDS\n",
    "\n",
    "[RAPIDS](https://rapids.ai/) is a suite of GPU accelerated data science libraries with APIs that should be familiar to users of Pandas, Dask, and Scikitlearn.\n",
    "\n",
    "This notebook focuses on showing how to use cuDF with Dask & XGBoost to scale GPU DataFrame ETL-style operations & model training out to multiple GPUs on mutliple nodes as part of Google Cloud Dataproc.\n",
    "\n",
    "Anaconda has graciously made some of the NYC Taxi dataset available in [a public Google Cloud Storage bucket](https://console.cloud.google.com/storage/browser/anaconda-public-data/nyc-taxi/csv/). We'll use our Dataproc Cluster of GPUs to process it and train a model that predicts the fare amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://test-m:8786\n",
       "  <li><b>Dashboard: </b><a href='http://test-m:8787/status' target='_blank'>http://test-m:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>12</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.142.0.62:8786' processes=11 cores=11>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba, xgboost, socket\n",
    "\n",
    "import dask, dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.delayed import delayed\n",
    "from dask.distributed import Client, wait\n",
    "\n",
    "# connect to the Dask cluster that Dataproc stood up\n",
    "client = Client(socket.gethostname()+':8786')\n",
    "# forces workers to restart. useful to ensure GPU memory is clear\n",
    "client.restart()\n",
    "\n",
    "# limit work-stealing as much as possible\n",
    "dask.config.set({'distributed.scheduler.work-stealing': False})\n",
    "dask.config.get('distributed.scheduler.work-stealing')\n",
    "dask.config.set({'distributed.scheduler.bandwidth': 1})\n",
    "dask.config.get('distributed.scheduler.bandwidth')\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the Data\n",
    "\n",
    "Now that we have a cluster of GPU workers, we'll use [dask-cudf](https://github.com/rapidsai/dask-cudf/) to load and parse a bunch of CSV files into a distributed DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2014-01-09 20:45:25</td>\n",
       "      <td>2014-01-09 20:52:31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-73.994770</td>\n",
       "      <td>40.736828</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.982227</td>\n",
       "      <td>40.731790</td>\n",
       "      <td>CRD</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2014-01-09 20:46:12</td>\n",
       "      <td>2014-01-09 20:55:12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-73.982392</td>\n",
       "      <td>40.773382</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.960449</td>\n",
       "      <td>40.763995</td>\n",
       "      <td>CRD</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2014-01-09 20:44:47</td>\n",
       "      <td>2014-01-09 20:59:46</td>\n",
       "      <td>2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-73.988570</td>\n",
       "      <td>40.739406</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.986626</td>\n",
       "      <td>40.765217</td>\n",
       "      <td>CRD</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2014-01-09 20:44:57</td>\n",
       "      <td>2014-01-09 20:51:40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-73.960213</td>\n",
       "      <td>40.770464</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.979863</td>\n",
       "      <td>40.777050</td>\n",
       "      <td>CRD</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2014-01-09 20:47:09</td>\n",
       "      <td>2014-01-09 20:53:32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-73.995371</td>\n",
       "      <td>40.717248</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.984367</td>\n",
       "      <td>40.720524</td>\n",
       "      <td>CRD</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vendor_id     pickup_datetime    dropoff_datetime   passenger_count  \\\n",
       "0       CMT 2014-01-09 20:45:25 2014-01-09 20:52:31                 1   \n",
       "1       CMT 2014-01-09 20:46:12 2014-01-09 20:55:12                 1   \n",
       "2       CMT 2014-01-09 20:44:47 2014-01-09 20:59:46                 2   \n",
       "3       CMT 2014-01-09 20:44:57 2014-01-09 20:51:40                 1   \n",
       "4       CMT 2014-01-09 20:47:09 2014-01-09 20:53:32                 1   \n",
       "\n",
       "    trip_distance   pickup_longitude   pickup_latitude   rate_code  \\\n",
       "0             0.7         -73.994770         40.736828           1   \n",
       "1             1.4         -73.982392         40.773382           1   \n",
       "2             2.3         -73.988570         40.739406           1   \n",
       "3             1.7         -73.960213         40.770464           1   \n",
       "4             0.9         -73.995371         40.717248           1   \n",
       "\n",
       "   store_and_fwd_flag   dropoff_longitude   dropoff_latitude  payment_type  \\\n",
       "0                   N          -73.982227          40.731790           CRD   \n",
       "1                   N          -73.960449          40.763995           CRD   \n",
       "2                   N          -73.986626          40.765217           CRD   \n",
       "3                   N          -73.979863          40.777050           CRD   \n",
       "4                   N          -73.984367          40.720524           CRD   \n",
       "\n",
       "    fare_amount   surcharge   mta_tax   tip_amount   tolls_amount  \\\n",
       "0           6.5         0.5       0.5         1.40            0.0   \n",
       "1           8.5         0.5       0.5         1.90            0.0   \n",
       "2          11.5         0.5       0.5         1.50            0.0   \n",
       "3           7.5         0.5       0.5         1.70            0.0   \n",
       "4           6.0         0.5       0.5         1.75            0.0   \n",
       "\n",
       "    total_amount  \n",
       "0           8.90  \n",
       "1          11.40  \n",
       "2          14.00  \n",
       "3          10.20  \n",
       "4           8.75  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = 'gcs://anaconda-public-data/nyc-taxi/csv/'\n",
    "\n",
    "df_2014 = dask_cudf.read_csv(base_path+'2014/yellow_*.csv')\n",
    "df_2014.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup\n",
    "\n",
    "As usual, the data needs to be massaged a bit before we can start adding features that are useful to an ML model.\n",
    "\n",
    "For example, in the 2014 taxi CSV files, there are `pickup_datetime` and `dropoff_datetime` columns. The 2015 CSVs have `tpep_pickup_datetime` and `tpep_dropoff_datetime`, which are the same columns. One year has `rate_code`, and another `RateCodeID`.\n",
    "\n",
    "Also, some CSV files have column names with extraneous spaces in them.\n",
    "\n",
    "Worst of all, starting in the July 2016 CSVs, pickup & dropoff latitude and longitude data were replaced by location IDs, making the second half of the year useless to us.\n",
    "\n",
    "We'll do a little string manipulation, column renaming, and concatenating of DataFrames to sidestep the problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of column names that need to be re-mapped\n",
    "remap = {}\n",
    "remap['tpep_pickup_datetime'] = 'pickup_datetime'\n",
    "remap['tpep_dropoff_datetime'] = 'dropoff_datetime'\n",
    "remap['ratecodeid'] = 'rate_code'\n",
    "\n",
    "#create a list of columns & dtypes the df must have\n",
    "must_haves = {\n",
    " 'pickup_datetime': 'datetime64[ms]',\n",
    " 'dropoff_datetime': 'datetime64[ms]',\n",
    " 'passenger_count': 'int32',\n",
    " 'trip_distance': 'float32',\n",
    " 'pickup_longitude': 'float32',\n",
    " 'pickup_latitude': 'float32',\n",
    " 'rate_code': 'int32',\n",
    " 'dropoff_longitude': 'float32',\n",
    " 'dropoff_latitude': 'float32',\n",
    " 'fare_amount': 'float32'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function which takes a DataFrame partition\n",
    "def clean_delayed(df_part, remap, must_haves):    \n",
    "    # some col-names include pre-pended spaces remove & lowercase column names\n",
    "    tmp = {col:col.strip().lower() for col in list(df_part.columns)}\n",
    "    df_part = df_part.rename(tmp)\n",
    "    \n",
    "    # rename using the supplied mapping\n",
    "    df_part = df_part.rename(remap)\n",
    "    \n",
    "    # iterate through columns in this df partition\n",
    "    for col in df_part.columns:\n",
    "        # drop anything not in our expected list\n",
    "        if col not in must_haves:\n",
    "            df_part = df_part.drop(col)\n",
    "            continue\n",
    "        \n",
    "        # if column was read as a string, recast as float\n",
    "        if df_part[col].dtype == 'object':\n",
    "            df_part[col] = df_part[col].str.fillna('-1')\n",
    "            df_part[col] = df_part[col].astype('float32')\n",
    "        else:\n",
    "            # downcast from 64bit to 32bit types\n",
    "            # Tesla T4 run slowly on 64 bit calcs\n",
    "            if 'int' in str(df_part[col].dtype):\n",
    "                df_part[col] = df_part[col].astype('int32')\n",
    "            if 'float' in str(df_part[col].dtype):\n",
    "                df_part[col] = df_part[col].astype('float32')\n",
    "            df_part[col] = df_part[col].fillna(-1)\n",
    "    \n",
    "    return df_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-09 20:45:25</td>\n",
       "      <td>2014-01-09 20:52:31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-73.994766</td>\n",
       "      <td>40.736828</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982224</td>\n",
       "      <td>40.731789</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-09 20:46:12</td>\n",
       "      <td>2014-01-09 20:55:12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-73.982391</td>\n",
       "      <td>40.773380</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.960449</td>\n",
       "      <td>40.763996</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-09 20:44:47</td>\n",
       "      <td>2014-01-09 20:59:46</td>\n",
       "      <td>2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-73.988571</td>\n",
       "      <td>40.739407</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.986626</td>\n",
       "      <td>40.765217</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-09 20:44:57</td>\n",
       "      <td>2014-01-09 20:51:40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-73.960213</td>\n",
       "      <td>40.770466</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979866</td>\n",
       "      <td>40.777050</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-09 20:47:09</td>\n",
       "      <td>2014-01-09 20:53:32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-73.995369</td>\n",
       "      <td>40.717247</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.984367</td>\n",
       "      <td>40.720524</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime    dropoff_datetime  passenger_count  trip_distance  \\\n",
       "0 2014-01-09 20:45:25 2014-01-09 20:52:31                1            0.7   \n",
       "1 2014-01-09 20:46:12 2014-01-09 20:55:12                1            1.4   \n",
       "2 2014-01-09 20:44:47 2014-01-09 20:59:46                2            2.3   \n",
       "3 2014-01-09 20:44:57 2014-01-09 20:51:40                1            1.7   \n",
       "4 2014-01-09 20:47:09 2014-01-09 20:53:32                1            0.9   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  rate_code  dropoff_longitude  \\\n",
       "0        -73.994766        40.736828          1         -73.982224   \n",
       "1        -73.982391        40.773380          1         -73.960449   \n",
       "2        -73.988571        40.739407          1         -73.986626   \n",
       "3        -73.960213        40.770466          1         -73.979866   \n",
       "4        -73.995369        40.717247          1         -73.984367   \n",
       "\n",
       "   dropoff_latitude  fare_amount  \n",
       "0         40.731789          6.5  \n",
       "1         40.763996          8.5  \n",
       "2         40.765217         11.5  \n",
       "3         40.777050          7.5  \n",
       "4         40.720524          6.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wraps dask.delayed function\n",
    "def clean(df):\n",
    "    parts = [dask.delayed(clean_delayed)(part, remap, must_haves) for part in df.to_delayed()]\n",
    "    return dask_cudf.from_delayed(parts)\n",
    "\n",
    "# actually clean and inspect the result\n",
    "df_2014 = clean(df_2014)\n",
    "df_2014.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing Our Training Data Size\n",
    "\n",
    "We still have 2015 and the first half of 2016's data to read and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = clean(dask_cudf.read_csv(base_path+'2015/yellow_*.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling 2016's Mid-Year Schema Change\n",
    "\n",
    "In 2016, only January - June CSVs have the columns we need. If we try to read `base_path+2016/yellow_*.csv`, Dask will not appreciate having differing schemas in the same DataFrame.\n",
    "\n",
    "Instead, we'll need to create a list of the valid months and read them independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gcs://anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-01.csv',\n",
       " 'gcs://anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-02.csv',\n",
       " 'gcs://anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-03.csv',\n",
       " 'gcs://anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-04.csv',\n",
       " 'gcs://anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-05.csv',\n",
       " 'gcs://anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-06.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months = [str(x).rjust(2, '0') for x in range(1, 7)]\n",
    "valid_files = [base_path+'2016/yellow_tripdata_2016-'+month+'.csv' for month in months]\n",
    "valid_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read & clean 2016 data and concat all DFs\n",
    "dfs_2016 = [clean(dask_cudf.read_csv(file)) for file in valid_files]\n",
    "\n",
    "# concatenate multiple DataFrames into one bigger one\n",
    "taxi_df = dask.dataframe.multi.concat([df_2014, df_2015] + dfs_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-09 20:45:25</td>\n",
       "      <td>2014-01-09 20:52:31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-73.994766</td>\n",
       "      <td>40.736828</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982224</td>\n",
       "      <td>40.731789</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-09 20:46:12</td>\n",
       "      <td>2014-01-09 20:55:12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-73.982391</td>\n",
       "      <td>40.773380</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.960449</td>\n",
       "      <td>40.763996</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-09 20:44:47</td>\n",
       "      <td>2014-01-09 20:59:46</td>\n",
       "      <td>2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-73.988571</td>\n",
       "      <td>40.739407</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.986626</td>\n",
       "      <td>40.765217</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-09 20:44:57</td>\n",
       "      <td>2014-01-09 20:51:40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-73.960213</td>\n",
       "      <td>40.770466</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979866</td>\n",
       "      <td>40.777050</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-09 20:47:09</td>\n",
       "      <td>2014-01-09 20:53:32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-73.995369</td>\n",
       "      <td>40.717247</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.984367</td>\n",
       "      <td>40.720524</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime    dropoff_datetime  passenger_count  trip_distance  \\\n",
       "0 2014-01-09 20:45:25 2014-01-09 20:52:31                1            0.7   \n",
       "1 2014-01-09 20:46:12 2014-01-09 20:55:12                1            1.4   \n",
       "2 2014-01-09 20:44:47 2014-01-09 20:59:46                2            2.3   \n",
       "3 2014-01-09 20:44:57 2014-01-09 20:51:40                1            1.7   \n",
       "4 2014-01-09 20:47:09 2014-01-09 20:53:32                1            0.9   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  rate_code  dropoff_longitude  \\\n",
       "0        -73.994766        40.736828          1         -73.982224   \n",
       "1        -73.982391        40.773380          1         -73.960449   \n",
       "2        -73.988571        40.739407          1         -73.986626   \n",
       "3        -73.960213        40.770466          1         -73.979866   \n",
       "4        -73.995369        40.717247          1         -73.984367   \n",
       "\n",
       "   dropoff_latitude  fare_amount  \n",
       "0         40.731789          6.5  \n",
       "1         40.763996          8.5  \n",
       "2         40.765217         11.5  \n",
       "3         40.777050          7.5  \n",
       "4         40.720524          6.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply a list of filter conditions to throw out records with missing or outlier values\n",
    "query_frags = [\n",
    "    'fare_amount > 0 and fare_amount < 500',\n",
    "    'passenger_count > 0 and passenger_count < 6',\n",
    "    'pickup_longitude > -75 and pickup_longitude < -73',\n",
    "    'dropoff_longitude > -75 and dropoff_longitude < -73',\n",
    "    'pickup_latitude > 40 and pickup_latitude < 42',\n",
    "    'dropoff_latitude > 40 and dropoff_latitude < 42'\n",
    "]\n",
    "taxi_df = taxi_df.query(' and '.join(query_frags))\n",
    "\n",
    "# inspect the results of cleaning\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Interesting Features\n",
    "\n",
    "Dask & cuDF provide standard DataFrame operations, but also let you run \"user defined functions\" on the underlying data.\n",
    "\n",
    "cuDF's [apply_rows](https://rapidsai.github.io/projects/cudf/en/0.6.0/api.html#cudf.dataframe.DataFrame.apply_rows) operation is similar to Pandas's [DataFrame.apply](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html), except that for cuDF, custom Python code is [JIT compiled by numba](https://numba.pydata.org/numba-doc/dev/cuda/kernels.html) into GPU kernels.\n",
    "\n",
    "We'll use a Haversine Distance calculation to find total trip distance, and extract additional useful variables from the datetime fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import cos, sin, asin, sqrt, pi\n",
    "\n",
    "def haversine_distance_kernel(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude, h_distance):\n",
    "    for i, (x_1, y_1, x_2, y_2) in enumerate(zip(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)):\n",
    "        x_1 = pi/180 * x_1\n",
    "        y_1 = pi/180 * y_1\n",
    "        x_2 = pi/180 * x_2\n",
    "        y_2 = pi/180 * y_2\n",
    "        \n",
    "        dlon = y_2 - y_1\n",
    "        dlat = x_2 - x_1\n",
    "        a = sin(dlat/2)**2 + cos(x_1) * cos(x_2) * sin(dlon/2)**2\n",
    "        \n",
    "        c = 2 * asin(sqrt(a)) \n",
    "        r = 6371 # Radius of earth in kilometers\n",
    "        \n",
    "        h_distance[i] = c * r\n",
    "\n",
    "def day_of_the_week_kernel(day, month, year, day_of_week):\n",
    "    for i, (d_1, m_1, y_1) in enumerate(zip(day, month, year)):\n",
    "        if month[i] <3:\n",
    "            shift = month[i]\n",
    "        else:\n",
    "            shift = 0\n",
    "        Y = year[i] - (month[i] < 3)\n",
    "        y = Y - 2000\n",
    "        c = 20\n",
    "        d = day[i]\n",
    "        m = month[i] + shift + 1\n",
    "        day_of_week[i] = (d + math.floor(m*2.6) + y + (y//4) + (c//4) -2*c)%7\n",
    "        \n",
    "def add_features_delayed(df):\n",
    "    df['hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['year'] = df['pickup_datetime'].dt.year\n",
    "    df['month'] = df['pickup_datetime'].dt.month\n",
    "    df['day'] = df['pickup_datetime'].dt.day\n",
    "    df['diff'] = df['dropoff_datetime'].astype('int64') - df['pickup_datetime'].astype('int64')\n",
    "    \n",
    "    df['pickup_latitude_r'] = df['pickup_latitude'].ceil()\n",
    "    df['pickup_longitude_r'] = df['pickup_longitude'].ceil()\n",
    "    df['dropoff_latitude_r'] = df['dropoff_latitude'].ceil()\n",
    "    df['dropoff_longitude_r'] = df['dropoff_longitude'].ceil()\n",
    "    \n",
    "    df = df.drop('pickup_datetime')\n",
    "    df = df.drop('dropoff_datetime')\n",
    "    \n",
    "    \n",
    "    df = df.apply_rows(haversine_distance_kernel,\n",
    "                   incols=['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'],\n",
    "                   outcols=dict(h_distance=np.float64),\n",
    "                   kwargs=dict())\n",
    "    \n",
    "    \n",
    "    df = df.apply_rows(day_of_the_week_kernel,\n",
    "                      incols=['day', 'month', 'year'],\n",
    "                      outcols=dict(day_of_week=np.float64),\n",
    "                      kwargs=dict())\n",
    "    \n",
    "    \n",
    "    df['is_weekend'] = (df['day_of_week']<2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>diff</th>\n",
       "      <th>pickup_latitude_r</th>\n",
       "      <th>pickup_longitude_r</th>\n",
       "      <th>dropoff_latitude_r</th>\n",
       "      <th>dropoff_longitude_r</th>\n",
       "      <th>h_distance</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-73.994766</td>\n",
       "      <td>40.736828</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982224</td>\n",
       "      <td>40.731789</td>\n",
       "      <td>6.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>426000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>1.196175</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-73.982391</td>\n",
       "      <td>40.773380</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.960449</td>\n",
       "      <td>40.763996</td>\n",
       "      <td>8.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>540000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>2.122098</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-73.988571</td>\n",
       "      <td>40.739407</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.986626</td>\n",
       "      <td>40.765217</td>\n",
       "      <td>11.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>899000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>2.874643</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-73.960213</td>\n",
       "      <td>40.770466</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979866</td>\n",
       "      <td>40.777050</td>\n",
       "      <td>7.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>403000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>1.809662</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-73.995369</td>\n",
       "      <td>40.717247</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.984367</td>\n",
       "      <td>40.720524</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>383000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>0.996204</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_count  trip_distance  pickup_longitude  pickup_latitude  \\\n",
       "0                1            0.7        -73.994766        40.736828   \n",
       "1                1            1.4        -73.982391        40.773380   \n",
       "2                2            2.3        -73.988571        40.739407   \n",
       "3                1            1.7        -73.960213        40.770466   \n",
       "4                1            0.9        -73.995369        40.717247   \n",
       "\n",
       "   rate_code  dropoff_longitude  dropoff_latitude  fare_amount  hour  year  \\\n",
       "0          1         -73.982224         40.731789          6.5    20  2014   \n",
       "1          1         -73.960449         40.763996          8.5    20  2014   \n",
       "2          1         -73.986626         40.765217         11.5    20  2014   \n",
       "3          1         -73.979866         40.777050          7.5    20  2014   \n",
       "4          1         -73.984367         40.720524          6.0    20  2014   \n",
       "\n",
       "   month  day    diff  pickup_latitude_r  pickup_longitude_r  \\\n",
       "0      1    9  426000               41.0               -73.0   \n",
       "1      1    9  540000               41.0               -73.0   \n",
       "2      1    9  899000               41.0               -73.0   \n",
       "3      1    9  403000               41.0               -73.0   \n",
       "4      1    9  383000               41.0               -73.0   \n",
       "\n",
       "   dropoff_latitude_r  dropoff_longitude_r  h_distance  day_of_week  \\\n",
       "0                41.0                -73.0    1.196175          4.0   \n",
       "1                41.0                -73.0    2.122098          4.0   \n",
       "2                41.0                -73.0    2.874643          4.0   \n",
       "3                41.0                -73.0    1.809662          4.0   \n",
       "4                41.0                -73.0    0.996204          4.0   \n",
       "\n",
       "   is_weekend  \n",
       "0       False  \n",
       "1       False  \n",
       "2       False  \n",
       "3       False  \n",
       "4       False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now add the features\n",
    "parts = [dask.delayed(add_features_delayed)(part) for part in taxi_df.to_delayed()]\n",
    "taxi_df = dask_cudf.from_delayed(parts)\n",
    "\n",
    "# inspect the result\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick a Training Set\n",
    "\n",
    "Let's imagine you're making a trip to New York on the 25th and want to build a model to predict what fare prices will be like the last few days of the month based on the first part of the month. We'll use a query expression to identify the `day` of the month to use to divide the data into train and test sets.\n",
    "\n",
    "The wall-time below represents how long it takes your GPU cluster to load data from the Google Cloud Storage bucket and the ETL portion of the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.56 s, sys: 88 ms, total: 7.65 s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = taxi_df.query('day < 25').persist()\n",
    "\n",
    "# create a Y_train ddf with just the target variable\n",
    "Y_train = X_train[['fare_amount']].persist()\n",
    "# drop the target variable from the training ddf\n",
    "X_train = X_train[X_train.columns.difference(['fare_amount'])]\n",
    "\n",
    "# this wont return until all data is in GPU memory\n",
    "done = wait([X_train, Y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286,955,292\n"
     ]
    }
   ],
   "source": [
    "# display how many records will be used in training\n",
    "def pretty_print(val):\n",
    "    print(\"{:,}\".format(val))\n",
    "\n",
    "pretty_print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the XGBoost Regression Model\n",
    "\n",
    "The wall time output below indicates how long it took your GPU cluster to train an XGBoost model over the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 296 ms, sys: 24 ms, total: 320 ms\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import dask_xgboost as dxgb_gpu\n",
    "\n",
    "params = {\n",
    " 'learning_rate': 0.3,\n",
    "  'max_depth': 8,\n",
    "  'objective': 'reg:squarederror',\n",
    "  'subsample': 0.6,\n",
    "  'gamma': 1,\n",
    "  'silent': True,\n",
    "  'verbose_eval': True,\n",
    "  'tree_method':'gpu_hist',\n",
    "  'n_gpus': 1\n",
    "}\n",
    "\n",
    "bst = dxgb_gpu.train(client, params, X_train, Y_train, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Good is Our Model?\n",
    "\n",
    "Now that we have a trained model, we need to test it with the 25% of records we held out.\n",
    "\n",
    "Based on the filtering conditions applied to this dataset, many of the DataFrame partitions will wind up having 0 rows.\n",
    "\n",
    "This is a problem for XGBoost which doesn't know what to do with 0 length arrays. We'll apply a bit of Dask logic to check for and drop partitions without any rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_partitions(df):\n",
    "    lengths = df.map_partitions(len).compute()\n",
    "    nonempty = [length > 0 for length in lengths]\n",
    "    return df.partitions[nonempty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72,909,669\n"
     ]
    }
   ],
   "source": [
    "X_test = taxi_df.query('day >= 25').persist()\n",
    "X_test = drop_empty_partitions(X_test)\n",
    "\n",
    "# Create Y_test with just the fare amount\n",
    "Y_test = X_test[['fare_amount']]\n",
    "\n",
    "# Drop the fare amount from X_test\n",
    "X_test = X_test[X_test.columns.difference(['fare_amount'])]\n",
    "\n",
    "# display test set size\n",
    "pretty_print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions on the test set\n",
    "Y_test['prediction'] = dxgb_gpu.predict(client, bst, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>prediction</th>\n",
       "      <th>squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205295</th>\n",
       "      <td>13.0</td>\n",
       "      <td>12.721198</td>\n",
       "      <td>0.077731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205431</th>\n",
       "      <td>7.5</td>\n",
       "      <td>7.618502</td>\n",
       "      <td>0.014043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205493</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.143480</td>\n",
       "      <td>0.020587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205805</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.957551</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206044</th>\n",
       "      <td>14.5</td>\n",
       "      <td>14.425009</td>\n",
       "      <td>0.005624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount  prediction  squared_error\n",
       "205295         13.0   12.721198       0.077731\n",
       "205431          7.5    7.618502       0.014043\n",
       "205493          8.0    8.143480       0.020587\n",
       "205805          8.0    7.957551       0.001802\n",
       "206044         14.5   14.425009       0.005624"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test['squared_error'] = (Y_test['prediction'] - Y_test['fare_amount'])**2\n",
    "\n",
    "# inspect the results to make sure our calculation looks right\n",
    "Y_test.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.851936673833718"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the actual RMSE over the full test set\n",
    "math.sqrt(Y_test.squared_error.mean().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! We can predict a taxi fare to within about $1.85.\n",
    "\n",
    "If I'm planning to head to Strata Data in NYC, I can probably fill out my ground transportation expense items ahead of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "\n",
    "We just demonstrated how to use GPU DataFrames to scale ETL style operations out to multiple GPUs on multiple nodes.\n",
    "\n",
    "We also showed how to pass prepared data directly to XGBoost without having the data ever leave GPU memory. As a result, we can run end to end data processing _and_ model training faster, using less hardware than with a CPU based solution.\n",
    "\n",
    "While other workflows will be more complex or operate on larger dataset sizes, our hope is that pre-processing and training on approximately 70GB (360 million rows) in about 3 and a half minutes shows that GPUs can offer speed ups that give Data Scientists less time to drink coffee, and more time to iterate on and tune model performance.\n",
    "\n",
    "What now?\n",
    "\n",
    "[Check out RAPIDS on GitHub](https://github.com/rapidsai) and follow the development, or pitch in by reporting issues, making pull requests or even just requesting the features your workflows need. We look forward to hearing from you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}