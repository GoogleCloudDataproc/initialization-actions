#!/bin/bash
#
[% INSERT legal/license_header %]
#
[% PROCESS common/template_disclaimer %]
#
# This script installs NVIDIA GPU drivers (version 550.135) along with
# CUDA 12.4.
#
# Additionally, it installs the RAPIDS Spark plugin, configures Spark
# and YARN, installs an agent to collect GPU utilization metrics.  The
# installer is compatible with Debian, Ubuntu, and Rocky Linux
# distributions.
#
# Note that the script is designed to work both when secure boot is
# enabled with a custom image and when disabled during cluster
# creation.
#
# For details see
# github.com/GoogleCloudDataproc/custom-images/tree/main/examples/secure-boot
#

set -euxo pipefail

[% INSERT common/util_functions %]

[% INSERT gpu/util_functions %]

function main() {
  setup_gpu_yarn

  echo "yarn setup complete"

  if [[ "${RAPIDS_RUNTIME}" == "SPARK" ]]; then
    install_spark_rapids
    configure_gpu_script
    echo "RAPIDS initialized with Spark runtime"
  elif [[ "${RAPIDS_RUNTIME}" == "DASK" ]]; then
    # we are not currently tooled for installing dask in this action.
    echo "RAPIDS recognizes DASK runtime - currently supported using dask/dask.sh or rapids/rapids.sh"
  else
    echo "Unrecognized RAPIDS Runtime: ${RAPIDS_RUNTIME}"
  fi

  # Restart YARN services if they are running already
  for svc in resourcemanager nodemanager; do
    if [[ "$(systemctl show hadoop-yarn-${svc}.service -p SubState --value)" == 'running' ]]; then
      systemctl  stop "hadoop-yarn-${svc}.service"
      systemctl start "hadoop-yarn-${svc}.service"
    fi
  done
  echo "main complete"
  return 0
}

function exit_handler() {
  gpu_exit_handler
  common_exit_handler
  return 0
}

function prepare_to_install(){
  prepare_common_env
  prepare_gpu_env
  trap exit_handler EXIT

  # Fetch instance roles and runtime
  readonly MASTER=$(/usr/share/google/get_metadata_value attributes/dataproc-master)
}

prepare_to_install

main
